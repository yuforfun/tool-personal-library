# ä¿®æ­£ [views/settings_view.py] å€å¡Š B: æ•´åˆå¼ä»‹é¢èˆ‡ AI é—œéµå­—ä¿®æ­£
# ä¿®æ­£åŸå› ï¼šç§»é™¤ Tabsï¼Œæ”¹ç‚ºä¸€ç›®ç­ç„¶çš„å„€è¡¨æ¿ä½ˆå±€ï¼›ä¿®æ­£ AI ä¿®å¾©åˆ¤å®šé—œéµå­—ã€‚
# æ›¿æ›/æ–°å¢æŒ‡ç¤ºï¼šè«‹å®Œå…¨æ›¿æ› views/settings_view.pyã€‚

import streamlit as st
import time
from modules import data_manager, services, ai_agent, scraper

def render_view():
    """æ¸²æŸ“è¨­å®šèˆ‡ç®¡ç†é é¢ (æ•´åˆç‰ˆ)"""
    st.header("âš™ï¸ è³‡æ–™è¨­å®šèˆ‡ç®¡ç†")
    st.caption("åœ¨æ­¤ç®¡ç†æ‚¨çš„æ•¸ä½è³‡ç”¢ï¼Œé€²è¡ŒåŒ¯å…¥åŒ¯å‡ºæˆ–ç³»çµ±ç¶­è­·ã€‚")
    
    st.divider()

    # === Part 1: è³‡æ–™äº¤æ›ä¸­å¿ƒ (Data Exchange) ===
    st.subheader("1. è³‡æ–™äº¤æ›ä¸­å¿ƒ")
    
    col_csv, col_json = st.columns(2, gap="large")
    
    # --- å·¦å´: é€šç”¨æ ¼å¼ (Excel/CSV) ---
    with col_csv:
        st.markdown("### ğŸ“Š Excel / CSV é€šç”¨æ ¼å¼")
        st.info("é©åˆã€Œæ‰¹æ¬¡ç·¨è¼¯ã€ã€ã€Œè³‡æ–™é·ç§»ã€æˆ–ã€Œçˆ¬èŸ²æ¸…å–®ã€ã€‚")
        
        # 1. åŒ¯å‡º
        csv_data = data_manager.export_csv()
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ CSV å ±è¡¨",
            data=csv_data,
            file_name="library_export.csv",
            mime="text/csv",
            use_container_width=True,
            help="åŒ…å«æ‰€æœ‰æ¬„ä½ï¼Œæ‚¨å¯ä»¥åœ¨ Excel ç·¨è¼¯å¾Œé‡æ–°åŒ¯å…¥ã€‚"
        )
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # 2. åŒ¯å…¥
        st.markdown("#### ğŸ“¤ åŒ¯å…¥ CSV")
        csv_file = st.file_uploader("ä¸Šå‚³ CSV", type=["csv"], key="csv_up", label_visibility="collapsed")
        
        if csv_file:
            result = data_manager.process_csv_import(csv_file)
            
            if result["status"] == "error":
                st.error(result["msg"])
            
            elif result["status"] == "success":
                mode = result.get("mode")
                
                if mode == "direct_insert":
                    st.success(f"âœ… è³‡æ–™å¯«å…¥æˆåŠŸï¼{result['msg']}")
                    if st.button("ğŸ”„ é‡æ–°æ•´ç†åˆ—è¡¨", key="refresh_csv"):
                        st.rerun()
                        
                elif mode == "crawl_list":
                    urls = result.get("crawl_urls", [])
                    st.warning(f"ğŸ“‹ åµæ¸¬åˆ° {len(urls)} å€‹ç¶²å€ (ç´”çˆ¬èŸ²æ¨¡å¼)")
                    
                    if st.button(f"ğŸš€ é–‹å§‹æ‰¹æ¬¡æŠ“å– ({len(urls)} æœ¬)", type="primary", use_container_width=True):
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        success_count = 0
                        
                        for i, url in enumerate(urls):
                            status_text.text(f"æ­£åœ¨è™•ç† ({i+1}/{len(urls)}): {url} ...")
                            try:
                                if services.add_book(url):
                                    success_count += 1
                            except: pass
                            progress_bar.progress((i + 1) / len(urls))
                            time.sleep(0.5)
                        
                        status_text.text("è™•ç†å®Œæˆï¼")
                        st.success(f"ğŸ‰ æ‰¹æ¬¡çµæŸï¼šæˆåŠŸ {success_count} æœ¬")
                        time.sleep(1)
                        st.rerun()

    # --- å³å´: ç³»çµ±å‚™ä»½ (JSON) ---
    with col_json:
        st.markdown("### ğŸ’¾ ç³»çµ±å®Œæ•´å‚™ä»½ (JSON)")
        st.warning("é©åˆã€Œæ•´æ©Ÿå‚™ä»½ã€æˆ–ã€Œé‚„åŸã€ã€‚åŒ…å«ç³»çµ± IDã€‚")
        
        # 1. åŒ¯å‡º
        json_str = data_manager.export_json()
        st.download_button(
            label="ğŸ“¦ ä¸‹è¼‰ç³»çµ±å‚™ä»½ (.json)",
            data=json_str,
            file_name="library_backup.json",
            mime="application/json",
            use_container_width=True
        )
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # 2. é‚„åŸ
        st.markdown("#### â™»ï¸ ç³»çµ±é‚„åŸ")
        json_file = st.file_uploader("ä¸Šå‚³å‚™ä»½æª”", type=["json"], key="json_up", label_visibility="collapsed")
        
        if json_file:
            content = json_file.getvalue().decode("utf-8")
            if st.button("âš ï¸ ç¢ºèªè¦†è“‹/é‚„åŸè³‡æ–™åº«", type="primary", use_container_width=True):
                res = data_manager.import_json(content)
                if res.get("status") == "success":
                    st.success(res.get("msg"))
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error(res.get("msg"))

    st.divider()

    # === Part 2: ç³»çµ±ç¶­è­· (System Ops) ===
    st.subheader("2. ç³»çµ±æ‰¹æ¬¡ç¶­è­·")
    
    # æƒææ¢ä»¶ä¿®æ­£ï¼šä½¿ç”¨ä½¿ç”¨è€…æŒ‡å®šçš„é—œéµå­—
    target_keyword = "å¾…è£œå®Œ (è«‹é»æ“Šé‡æ–°åˆ†æ)"
    
    books = services.get_books()
    # é‚è¼¯ï¼šæƒæ AI åˆ†ææ¬„ä½æ˜¯å¦åŒ…å«è©²é—œéµå­—ï¼Œæˆ–æ˜¯ç©ºçš„
    target_books = [
        b for b in books 
        if not b.ai_plot_analysis 
        or target_keyword in b.ai_plot_analysis 
        or b.ai_summary == "CSV åŒ¯å…¥è³‡æ–™"
    ]
    
    col_ops_Info, col_ops_Action = st.columns([3, 1])
    
    with col_ops_Info:
        st.markdown("#### ğŸ¤– AI è³‡æ–™è£œå…¨")
        if not target_books:
            st.success("âœ¨ ç›®å‰è³‡æ–™åº«å¥åº·ï¼Œæ²’æœ‰éœ€è¦ä¿®å¾©çš„æ›¸ç±ã€‚")
        else:
            st.info(f"ğŸ” æƒæç™¼ç¾ **{len(target_books)}** æœ¬æ›¸ç±éœ€è¦ AI åˆ†æã€‚")
            with st.expander("æŸ¥çœ‹æ¸…å–®"):
                for b in target_books:
                    st.text(f"- {b.title}")

    with col_ops_Action:
        st.markdown("<br>", unsafe_allow_html=True)
        if target_books:
            if st.button(f"ğŸš€ å•Ÿå‹•ä¿®å¾© ({len(target_books)})", type="primary", use_container_width=True):
                progress_bar = st.progress(0)
                status_box = st.empty()
                success = 0
                
                for i, book in enumerate(target_books):
                    status_box.markdown(f"**æ­£åœ¨åˆ†æ**: {book.title} ...")
                    
                    # å˜—è©¦é‡æ–°çˆ¬å– + AI
                    raw_data = scraper.scrape_book(book.url)
                    if raw_data:
                        ai_res = ai_agent.analyze_book(raw_data)
                        if ai_res:
                            book.title = raw_data.title
                            book.author = raw_data.author
                            book.official_desc = raw_data.description
                            book.tags = ai_res.tags
                            book.ai_summary = ai_res.summary
                            book.ai_plot_analysis = ai_res.plot
                            services.save_book_changes(book)
                            success += 1
                    
                    progress_bar.progress((i + 1) / len(target_books))
                    time.sleep(1)
                
                status_box.success(f"âœ… ä¿®å¾©å®Œæˆï¼æˆåŠŸ {success} æœ¬")
                time.sleep(2)
                st.rerun()

# // åŠŸèƒ½: è¨­å®šé é¢ UI (æ•´åˆç‰ˆ)