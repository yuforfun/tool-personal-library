# æ–°å¢ [test_ai_agent.py] å€å¡Š A: AI æ¨¡çµ„ç¨ç«‹æ¸¬è©¦
# ä¿®æ­£åŸå› ï¼šé©—è­‰çˆ¬èŸ²èˆ‡ AI æ¨¡çµ„çš„ä¸²æ¥ï¼Œä¸¦æ¸¬è©¦ gemini-2.5-pro çš„å›æ‡‰æ•ˆæœã€‚
# æ›¿æ›/æ–°å¢æŒ‡ç¤ºï¼šé€™æ˜¯æ–°æª”æ¡ˆï¼Œè«‹æ”¾ç½®æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ã€‚

from modules.scraper import scrape_book
from modules.ai_agent import analyze_book
import sys
import io

# å¼·åˆ¶è¨­å®šæ¨™æº–è¼¸å‡ºç·¨ç¢¼ç‚º utf-8 (é¿å… Windows çµ‚ç«¯æ©Ÿäº‚ç¢¼)
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def main():
    print("=== é–‹å§‹é€²è¡Œ AI æ¯’èˆŒæ›¸è©•æ¸¬è©¦ ===\n")
    
    # æ¸¬è©¦ç¶²å€ï¼šéš¨ä¾¿æŒ‘ä¸€æœ¬çœ‹èµ·ä¾†å¾ˆå¥—è·¯çš„æ›¸ä¾†æ¸¬è©¦æ¯’èˆŒæ•ˆæœ
    # é€™è£¡é è¨­ä½¿ç”¨å‰›å‰›æ¸¬è©¦éçš„æ™‰æ±Ÿç¶²å€ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ›æˆå…¶ä»–çš„
    test_url = "https://www.banxia.la/books/349286.html" 
    
    # 1. å…ˆçˆ¬èŸ²
    print(f"STEP 1: çˆ¬å–ç¶²é  {test_url}")
    raw_data = scrape_book(test_url)
    
    if not raw_data:
        print("âŒ çˆ¬èŸ²å¤±æ•—ï¼Œç„¡æ³•é€²è¡Œ AI åˆ†æ")
        return

    print(f"âœ… çˆ¬å–æˆåŠŸï¼š{raw_data.title} / {raw_data.author}\n")

    # 2. å† AI åˆ†æ
    print(f"STEP 2: å‘¼å« Gemini-2.5-pro é€²è¡Œæ¯’èˆŒåˆ†æ...")
    ai_result = analyze_book(raw_data)
    
    if ai_result:
        print("\n" + "="*40)
        print(f"æ›¸åï¼š{raw_data.title}")
        print("="*40)
        print(f"ğŸ·ï¸  æ¨™ç±¤ï¼š{', '.join(ai_result.tags)}")
        print(f"ğŸ˜ˆ æ¯’èˆŒçŸ­è©•ï¼š{ai_result.summary}")
        print("-" * 40)
        print(f"ğŸ“– åŠ‡æƒ…æ‘˜è¦ï¼š\n{ai_result.plot}")
        print("="*40 + "\n")
    else:
        print("âŒ AI åˆ†æå¤±æ•—")

if __name__ == "__main__":
    main()

# // åŠŸèƒ½: AI åŠŸèƒ½é©—è­‰è…³æœ¬
# // input: å…§å»ºæ¸¬è©¦ç¶²å€
# // output: çµ‚ç«¯æ©Ÿåˆ—å° AI æ¯’èˆŒè©•è«–